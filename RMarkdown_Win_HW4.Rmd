---
title: "STATS 418 Homework 4"
author: "Yuan Yi Chen (Eve)"
date: "2017/6/7"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r, include = F}
setwd("C:/Users/Eve/Dropbox/UCLA Files/Courses/418 Tools of Data Science/STATS 418 - HW4")
```
##***Agenda**
***

###**A. Introduction**
###**B. Brief Summarization**
###**C. Take a Look of Our Data**
###**D. Visualization of Our Data**
###**E. Models**
###**F. Conclusion**

  

***

###**A. Introduction**

####This data is provided a Portuguese banking institution which conducted a marketing campaigns to promote their product. Our goal is to predict if the client will subscribe a term deposit (variable y). We will run several models including neural network, random search (GBM), ensemble, random forest, GBM and logistic regression models. We hope to know:
  * The trade off between training time and accuracy.
  * Will feature selection increases the accuracy?


####The general steps are
  * Manipulate our data set (data wrangling & graphs)
  * Apply different models to the clean data set (with all features)
  * Make prediction and view the accuracy and ROC curve
  * Do feature selection (variable importance)
  * Rebuild models based on limited features
  * Make prediction, AUC and ROC curve (with limited features)

####In order to let readers view the explicit results, I would only include 6 models in this report. That is, regarding to neural network models, only the model with highest AUC will be included in this report. **Please refer to the another html file if you want to view the whole results of totally 26 models**.

***

###**B. Brief Summarization** 

#####From the following table, We can clearly see that all the AUCs of models fall between 0.9 and 0.94. This means after we train and validate our data set, the prediction of whether consumers will subscribe a product has a high AUC between 0.9 and 0.94.

Models | AUC | Processing time (Sec)        
----|---------|----------------------------------------------
**Neural Network (the best model within all NN models)**| 0.9260857 | 472.45
**Random Search (with GBM algorithm)**| 0.9243476  |109.78
**Ensemble (random forest + GBM + NN)**| 0.929771 | 2.57
**GBM**| 0.9287117 | 31.65
**Random Forest**| 0.926403 | 29.78
**Logistic Regression**| 0.9049404 | 2.79

#####In a tradeoff perspective, we can further think about the tradeoff between accuracy(AUC) and the processing time. For example, although the logistic regression has the smallest processing time, its accuracy falls behind other models. Generally speaking, it's not a bad model because perhaps 2~3% AUC difference may not have great impact to our prediction. However, If it's the bioinformatic data, then it's worth to spend lots of time and CPU/GPC to get the model because even 0.01% increases of AUC can benefit the society.


#####In sum, it seems to me that I would choose the logistic model because of its short processing time. In the marketing world, timing and the feedback from our customers are the most important things. As an analyst in this bank who co-works with the marketing team, I am more prone to send the results to the marketing team for them to modify their marketing strategy.

#####On the other hand, if this bank pursues the accuracy (AUC), I may use random forest model instead. It's because although the ensemble model increase the AUC for around 0.001, random forest has the shortest processing time. Furthermore, if we have enough computational resources, we can increase the amount of trees to have higher accuracy. This may not cause the overfitting.

***

###**C. Take a Look of Our Data**

```{r, include = F}
#Remove Objects
rm(list=ls())

#Clear Memory
gc(reset=TRUE)

#directory
setwd("C:/Users/Eve/Dropbox/UCLA Files/Courses/418 Tools of Data Science/STATS 418 - HW4")

#Packages
library(readr)   #Use to read data
library(glmnet)  #Use to apply logistic regression
library(ROCR)    #Use to calcuate AUC
library(h2o)     #Use to run logistic regression and random forest 
library(xgboost) #Use to run random forest model
library(ggplot2) #Use to draw plots
library(dplyr)
```

#####We totally have 45211 observations, 15 input variables and 1 output variables (y). The description of features are list as following:


Feature |  Type | Description        
----|-----------|--------------------------------------------
job|Categorical |Type of job, categorical: 'admin.','blue-collar','entrepreneur',etc...
marital| Categorical |Marital status, categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed
education| Categorical | "unknown","secondary","primary","tertiary"
balance| Numeric | Average yearly balance, in euros 
age| Numeric | age
housing| Binary |Has housing loan? (binary: "Y","N")
loan| Binary | Has personal loan? (binary: "Y","N")
contact| Categorical | Contact communication type, categorical: "unknown","telephone","cellular"
day| Numeric |Last contact day of the month
month | Categorical |Last contact month of year, categorical: "jan", "feb", "mar", ..., "nov", "dec"
duration |Numeric |Last contact duration, in seconds
campaign |Numeric |Number of contacts performed during this campaign and for this client
pdays |Numeric |Number of days that passed by after the client was last contacted from a previous campaign
previous |Numeric |Number of contacts performed before this campaign and for this client
poutcome|Categorical |Outcome of the previous marketing campaign, categorical: "unknown","other","failure","success"
**y (output)** |Binary |Has the client subscribed a term deposit? (binary: "Y","N")

#####This is our data set
```{r, include = F}
data <- read.csv("test.csv")
```

```{r, echo = F}
head(data, 3)
```

###**D. Visualization of Our Data**

#####Make several plots to have brief understanding about our data set
Features | People who tend to subscribe the product
---------|-----------------------------------------
Job | Work in management field
Martial | Married people
Education | People who has secondary degree
Age | People whose age is between 20 to 40 years old
Housing | People who has no house
Loan | People who don't have the loan
Contact | Contact communication type is Cellular
Day | People tend to subscribe the product on 30th
Month | People tend to subscribe the product on May
Campaign | 1 contact performed during this campaign and for this client
Previous | People who haven't been contacted before this campaign
Poutcome | Outcome of the previous marketing is "Success"

***

```{r, include = F}
#Original data set
data <- read.csv("test.csv")
#Subscription data set (consumers did subscribe the product)
subscribe <- data[which(data$y == "Y"),]
```

```{r, include=FALSE}
#####Job vs subscription
data_job = subscribe %>%
  group_by(job) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
ggplot(data=data_job, aes(x=job, y=n))+
  geom_bar(stat = "identity", aes(fill = job))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different Types of Jobs") + ylab("Numbers of Subscriptions") + ggtitle("Job v.s. Subscription")
```

```{r, include=FALSE}
#####marital vs subscription
data_marital = subscribe %>%
  group_by(marital) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#marital v.s. Subscription
ggplot(data=data_marital, aes(x=marital, y=n))+
  geom_bar(stat = "identity", aes(fill = marital))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different Marital Status") + ylab("Numbers of Subscriptions") + ggtitle("Marital v.s. Subscription")
```


```{r, include=FALSE}
#####education vs subscription
data_education = subscribe %>%
  group_by(education) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#education v.s. Subscription
ggplot(data=data_education, aes(x=education, y=n))+
  geom_bar(stat = "identity", aes(fill = education))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different Education Background") + ylab("Numbers of Subscriptions") + ggtitle("Education v.s. Subscription")
```



```{r, include=FALSE}
#####age vs subscription
data_age = subscribe %>%
  group_by(age) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#age v.s. Subscription
ggplot(data=data_age, aes(x=age, y=n))+
  geom_bar(stat = "identity", aes(fill = age))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different age") + ylab("Numbers of Subscriptions") + ggtitle("Age v.s. Subscription")
```

```{r, include=FALSE}
#####housing vs subscription
data_housing = subscribe %>%
  group_by(housing) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#housing v.s. Subscription
ggplot(data=data_housing, aes(x=housing, y=n))+
  geom_bar(stat = "identity", aes(fill = housing))+ 
  theme_bw()+ coord_flip() + 
  xlab("Housing") + ylab("Numbers of Subscriptions") + ggtitle("Housing v.s. Subscription")
```


```{r, include=FALSE}
#####loan vs subscription
data_loan = subscribe %>%
  group_by(loan) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#balance v.s. Subscription
ggplot(data=data_loan, aes(x=loan, y=n))+
  geom_bar(stat = "identity", aes(fill = loan))+ 
  theme_bw()+ coord_flip() + 
  xlab("Loan") + ylab("Numbers of Subscriptions") + ggtitle("Loan v.s. Subscription")
```



```{r, include=FALSE}
#####contact vs subscription
data_contact = subscribe %>%
  group_by(contact) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#contact v.s. Subscription
ggplot(data=data_contact, aes(x=contact, y=n))+
  geom_bar(stat = "identity", aes(fill = contact))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different contact") + ylab("Numbers of Subscriptions") + ggtitle("Contact v.s. Subscription")
```


```{r, include=FALSE}
#####day vs subscription
data_day = subscribe %>%
  group_by(day) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#balance v.s. Subscription
ggplot(data=data_day, aes(x=day, y=n))+
  geom_bar(stat = "identity", aes(fill = day))+ 
  theme_bw()+ coord_flip() + 
  xlab("Days") + ylab("Numbers of Subscriptions") + ggtitle("Days v.s. Subscription")
```



```{r, include=FALSE}
#####month vs subscription
data_month = subscribe %>%
  group_by(month) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#month v.s. Subscription
ggplot(data=data_month, aes(x=month, y=n))+
  geom_bar(stat = "identity", aes(fill = month))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different Month") + ylab("Numbers of Subscriptions") + ggtitle("Month v.s. Subscription")
```



```{r, include=FALSE}
#####duration vs subscription
data_duration = subscribe %>%
  group_by(duration) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#duration v.s. Subscription
ggplot(data=data_duration, aes(x=duration, y=n))+
  geom_bar(stat = "identity", aes(fill = duration))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different duration") + ylab("Numbers of Subscriptions") + ggtitle("Duration v.s. Subscription")
```



```{r, include=FALSE}
#####campaign vs subscription
data_campaign = subscribe %>%
  group_by(campaign) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#campaign v.s. Subscription
ggplot(data=data_campaign, aes(x=campaign, y=n))+
  geom_bar(stat = "identity", aes(fill = campaign))+ 
  theme_bw()+ coord_flip() + 
  xlab("Numbers of Campaign") + ylab("Numbers of Subscriptions") + ggtitle("Campaign v.s. Subscription")
```




```{r, include=FALSE}
#####poutcome vs subscription
data_poutcome = subscribe %>%
  group_by(poutcome) %>%
  summarise(n = n())
```
```{r, echo = FALSE}
#poutcome v.s. Subscription
ggplot(data=data_poutcome, aes(x=poutcome, y=n))+
  geom_bar(stat = "identity", aes(fill = poutcome))+ 
  theme_bw()+ coord_flip() + 
  xlab("Different Poutcome") + ylab("Numbers of Subscriptions") + ggtitle("Poutcome v.s. Subscription")
```


###**E. Models, AUC and ROC**

```{r, include = F}
library(h2o)
```
```{r, include = F}
h2o.no_progress()
```

```{r, include = F}
h2o.init(nthreads=-1)
```

```{r, include=F}
#Data sets with validation
dx <- h2o.importFile("test.csv")
dx_split <- h2o.splitFrame(dx, ratios = c(0.6,0.2), seed = 123)
dx_train <- dx_split[[1]]
dx_valid <- dx_split[[2]]
dx_test <- dx_split[[3]]
Xnames <- setdiff(names(dx_train),"y")
```



####**1. GBM**

```{r}
system.time({
  md_gbm <- h2o.gbm(x = Xnames, y = "y", training_frame = dx_train, distribution = "bernoulli", ntrees = 50, max_depth = 10, learn_rate = 0.1, nbins = 100, seed = 123, nfolds = 5, fold_assignment = "Modulo", keep_cross_validation_predictions = TRUE)    
})
```

```{r}
h2o.auc(h2o.performance(md_gbm, dx_test))
```

***


####**2. Random Forest**
```{r}
system.time({
  md_rf <- h2o.randomForest(x = Xnames, y = "y", training_frame = dx_train, ntrees = 50, seed = 123, nfolds = 5, fold_assignment = "Modulo", keep_cross_validation_predictions = TRUE)
})
```

```{r}
h2o.auc(h2o.performance(md_rf, dx_test))
```

***

####**3. Logistic Regression**
```{r}
system.time({
  md_logistic <- h2o.glm(x = Xnames, y = "y", training_frame = dx_train, 
                family = "binomial", 
                alpha = 1, lambda = 0,
                seed = 123,
                nfolds = 5, fold_assignment = "Modulo", keep_cross_validation_predictions = TRUE)
})
```
```{r}
h2o.auc(h2o.performance(md_logistic, dx_test))
```

####**4. Neural Network Model**

```{r}
system.time({
  md_nn <- h2o.deeplearning(x = Xnames, y = "y", training_frame = dx_train, activation = "Rectifier", hidden = c(100,100),adaptive_rate = FALSE, rate = 0.01, rate_annealing = 1e-04,momentum_start = 0.5, momentum_ramp = 1e5, momentum_stable = 0.99, epochs = 100, seed = 123, nfolds = 5, fold_assignment = "Modulo", keep_cross_validation_predictions = TRUE)
  })
```

```{r}
#AUC
h2o.performance(md_nn, dx_test)@metrics$AUC
```
***

####**5. Ensemble (random forest, GBM and neural network)**

#####*Notes: From the following result, we can see that the random forest model plays an important role in our ensemble model. Whereas the neural network model has the smallest impact on the ensemble model.*

```{r}
system.time({
md_ensemble <- h2o.stackedEnsemble(x = Xnames, y = "y", training_frame = dx_train,base_models = list(md_rf@model_id, md_gbm@model_id, md_nn@model_id))
})
```

Check the AUC of Ensemble model
```{r}
h2o.auc(h2o.performance(md_ensemble, dx_test))
```

Coefficients of ensemble
```{r}
h2o.getModel(md_ensemble@model$metalearner$name)@model$coefficients_table
```

####**6. Random Search (GBM)**

Step1: Change Xnames to Xnames_rs because random search uses different function instead of "setdiff"
*Notes: Originally, Xnames is 
Xnames <- setdiff(names(dx_train),"y")*
```{r, message = F}
Xnames_rs <- names(dx_train)[which(names(dx_train)!="y")]
```

Step2: Create list of hyperparameters

```{r}
hyper_params <- list( ntrees = 10000,  ## early stopping
                      max_depth = 5:15, 
                      min_rows = c(1,3,10,30,100),
                      learn_rate = c(0.01,0.03,0.1),  
                      learn_rate_annealing = c(0.99,0.995,1,1),
                      sample_rate = c(0.4,0.7,1,1),
                      col_sample_rate = c(0.7,1,1),
                      nbins = c(30,100,300),
                      nbins_cats = c(64,256,1024)
)
```

Step3: Create list of search criteria

```{r}
search_criteria <- list( strategy = "RandomDiscrete",
                         max_runtime_secs = 10*3600,
                         max_models = 10
)
```

Step4: Apply random search with GBM model 
```{r}
system.time({
  md_rs <- h2o.grid(algorithm = "gbm", grid_id = "grd",
                  x = Xnames_rs, y = "y", training_frame = dx_train,
                  validation_frame = dx_valid,
                  hyper_params = hyper_params,
                  search_criteria = search_criteria,
                  stopping_metric = "AUC", stopping_tolerance = 1e-3, stopping_rounds = 2,
                  seed = 123)
})
```


Step5: Make prediction and calculate AUC
```{r}
#To sort
md_rs <- h2o.getGrid(grid_id = "grd", sort_by = "auc", decreasing = TRUE)
```

```{r}
#To see the best
md_rs_best <- h2o.getModel(md_rs@model_ids[[1]])
```

```{r}
#AUC 
auc_rs <- h2o.auc(h2o.performance(md_rs_best, dx_test))
auc_rs
```




***

###**F. Conclusion**
#####After applying 25 models with the same data, we select only 6 models to further explore which model performs the best. The main conclusion is that I may use random forest model in this case. 

#####Although the AUC of random forest model is not higher than random search (GBM) or ensemble models, its processing time is shorter than both random search and ensemble models.  On the other hand, random forest model will not cause overfitting even if we increase the amount of trees. Furthermore, we can even use varImpPlot function to see the importance of each feature, which may benefit our feature selection process.




###This is the end of the homework 4. Thank you for your reading! :)

***

